{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ce5d303",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Song Recommendation Model\n",
    "\n",
    "**Objective:** Build a similarity-based music recommendation system using k-nearest neighbors (k-NN) algorithm with euclidean distance calculations.\n",
    "\n",
    "**Input:** `../data/processed/spotify_tracks_features_engineered.csv` (standardized audio features)  \n",
    "**Process:** Load → Build k-NN Model → Generate Recommendations → Format Output  \n",
    "**Output:** Recommendation dataset matching `recommendation_sample_enhanced.csv` format\n",
    "\n",
    "**Algorithm:** k-NN with k=10 neighbors using euclidean distance on standardized audio features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6e5b8c",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & Library Imports\n",
    "\n",
    "Import essential libraries for machine learning, data manipulation, and distance calculations. We'll use scikit-learn's NearestNeighbors for efficient k-NN implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c88c8d90",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpairwise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m euclidean_distances\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# For progress tracking\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Display configuration\u001b[39;00m\n\u001b[32m     15\u001b[39m pd.set_option(\u001b[33m'\u001b[39m\u001b[33mdisplay.max_columns\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m50\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# For progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Display configuration\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"Ready to build k-NN recommendation model...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c3523d",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Exploration\n",
    "\n",
    "Load the feature-engineered dataset containing both original and standardized audio features. We'll examine the structure to understand our feature matrix for k-NN calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9913a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "INPUT_CSV = Path(\"../data/processed/spotify_tracks_features_engineered.csv\")\n",
    "SAMPLE_OUTPUT = Path(\"../data/processed/recommendation_sample_enhanced.csv\")\n",
    "OUTPUT_CSV = Path(\"../data/processed/knn_recommendations.csv\")\n",
    "\n",
    "print(f\"Input file: {INPUT_CSV.resolve()}\")\n",
    "print(f\"Sample format file: {SAMPLE_OUTPUT.resolve()}\")\n",
    "print(f\"Output file: {OUTPUT_CSV.resolve()}\")\n",
    "\n",
    "# Load feature-engineered dataset\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "    print(f\"\\nDataset loaded successfully!\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {len(df.columns)}\")\n",
    "    display(df.head(3))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find {INPUT_CSV}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e177efc",
   "metadata": {},
   "source": [
    "## 3. Examine Target Output Format\n",
    "\n",
    "Load and analyze the expected output format to ensure our recommendations match the required structure for the recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb23a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample output format to understand required structure\n",
    "try:\n",
    "    sample_format = pd.read_csv(SAMPLE_OUTPUT)\n",
    "    print(\"Target output format structure:\")\n",
    "    print(f\"Shape: {sample_format.shape}\")\n",
    "    print(f\"Columns: {sample_format.columns.tolist()}\")\n",
    "    display(sample_format.head())\n",
    "    \n",
    "    # Understand the format requirements\n",
    "    print(\"\\nFormat Analysis:\")\n",
    "    print(f\"- Total recommendations: {len(sample_format)}\")\n",
    "    print(f\"- Unique source tracks: {sample_format['track_id'].nunique()}\")\n",
    "    print(f\"- Recommendations per track: {len(sample_format) // sample_format['track_id'].nunique()}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Sample format file not found. Will create standard format.\")\n",
    "    sample_format = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b2d25",
   "metadata": {},
   "source": [
    "## 4. Prepare Feature Matrix for k-NN\n",
    "\n",
    "Extract the standardized audio features that will be used for euclidean distance calculations. These features have been normalized to have mean=0 and std=1, ensuring equal contribution to distance measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b9c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify standardized audio features for k-NN model\n",
    "scaled_features = [col for col in df.columns if col.endswith('_scaled')]\n",
    "\n",
    "print(f\"Standardized audio features for k-NN: {len(scaled_features)}\")\n",
    "print(scaled_features)\n",
    "\n",
    "# Verify we have the expected 12 audio features\n",
    "expected_features = [\n",
    "    'danceability_scaled', 'energy_scaled', 'key_scaled', 'loudness_scaled',\n",
    "    'mode_scaled', 'speechiness_scaled', 'acousticness_scaled', \n",
    "    'instrumentalness_scaled', 'liveness_scaled', 'valence_scaled', \n",
    "    'tempo_scaled', 'time_signature_scaled'\n",
    "]\n",
    "\n",
    "missing_features = [f for f in expected_features if f not in scaled_features]\n",
    "if missing_features:\n",
    "    print(f\"\\nWarning: Missing expected features: {missing_features}\")\n",
    "else:\n",
    "    print(\"\\nAll expected standardized features found ✓\")\n",
    "\n",
    "# Create feature matrix for k-NN\n",
    "feature_matrix = df[scaled_features].values\n",
    "print(f\"\\nFeature matrix shape: {feature_matrix.shape}\")\n",
    "print(f\"Feature matrix type: {type(feature_matrix)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97621136",
   "metadata": {},
   "source": [
    "## 5. Build k-Nearest Neighbors Model\n",
    "\n",
    "Initialize and fit the k-NN model using euclidean distance. We'll use k=11 (to get 10 recommendations excluding the input song itself) and euclidean distance metric for similarity calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872aec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize k-NN model\n",
    "# Using k=11 to get 10 recommendations (excluding the query song itself)\n",
    "k_neighbors = 11\n",
    "knn_model = NearestNeighbors(\n",
    "    n_neighbors=k_neighbors,\n",
    "    metric='euclidean',\n",
    "    algorithm='auto',  # Let sklearn choose the best algorithm\n",
    "    n_jobs=-1  # Use all available CPU cores for faster computation\n",
    ")\n",
    "\n",
    "print(f\"Initializing k-NN model with:\")\n",
    "print(f\"- k = {k_neighbors} neighbors (10 recommendations + 1 self)\")\n",
    "print(f\"- Distance metric: euclidean\")\n",
    "print(f\"- Algorithm: auto (sklearn will choose optimal)\")\n",
    "\n",
    "# Fit the model with our standardized feature matrix\n",
    "print(\"\\nFitting k-NN model...\")\n",
    "knn_model.fit(feature_matrix)\n",
    "print(\"k-NN model fitted successfully!\")\n",
    "\n",
    "# Test the model with a sample query\n",
    "print(\"\\nTesting model with first track:\")\n",
    "sample_distances, sample_indices = knn_model.kneighbors([feature_matrix[0]])\n",
    "print(f\"Found {len(sample_indices[0])} neighbors\")\n",
    "print(f\"Distances: {sample_distances[0][:5]}...\")  # Show first 5 distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d6d4b2",
   "metadata": {},
   "source": [
    "## 6. Generate Recommendations Function\n",
    "\n",
    "Create a function to generate recommendations for any given track. This function will find the k-nearest neighbors and return track information excluding the input song itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b6c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(track_index, n_recommendations=10):\n",
    "    \"\"\"\n",
    "    Get song recommendations for a given track using k-NN model.\n",
    "    \n",
    "    Args:\n",
    "        track_index (int): Index of the track in the dataset\n",
    "        n_recommendations (int): Number of recommendations to return\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with recommended tracks\n",
    "    \"\"\"\n",
    "    # Get k+1 neighbors (including the track itself)\n",
    "    distances, indices = knn_model.kneighbors([feature_matrix[track_index]], \n",
    "                                            n_neighbors=n_recommendations+1)\n",
    "    \n",
    "    # Remove the first result (the track itself) and get recommendations\n",
    "    neighbor_indices = indices[0][1:n_recommendations+1]  # Exclude self\n",
    "    neighbor_distances = distances[0][1:n_recommendations+1]  # Exclude self\n",
    "    \n",
    "    # Get track information for recommendations\n",
    "    recommended_tracks = df.iloc[neighbor_indices].copy()\n",
    "    \n",
    "    # Add similarity score (inverse of distance - higher score = more similar)\n",
    "    recommended_tracks['similarity_score'] = 1 / (1 + neighbor_distances)\n",
    "    recommended_tracks['euclidean_distance'] = neighbor_distances\n",
    "    \n",
    "    return recommended_tracks\n",
    "\n",
    "# Test the recommendation function\n",
    "print(\"Testing recommendation function with track index 0:\")\n",
    "sample_track = df.iloc[0]\n",
    "print(f\"Source track: '{sample_track['track_name']}' by {sample_track['artists']}\")\n",
    "\n",
    "sample_recs = get_recommendations(0, n_recommendations=5)\n",
    "print(f\"\\nTop 5 recommendations:\")\n",
    "for i, (_, track) in enumerate(sample_recs.iterrows(), 1):\n",
    "    print(f\"{i}. '{track['track_name']}' by {track['artists']} (distance: {track['euclidean_distance']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a2efa2",
   "metadata": {},
   "source": [
    "## 7. Generate Recommendations for All Tracks\n",
    "\n",
    "Process the entire dataset to generate 10 recommendations for each track. This creates a comprehensive recommendation dataset for the entire music catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eea9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations for all tracks\n",
    "print(\"Generating recommendations for all tracks...\")\n",
    "print(f\"Processing {len(df)} tracks to generate {len(df) * 10:,} total recommendations\")\n",
    "\n",
    "all_recommendations = []\n",
    "\n",
    "# Process tracks in batches with progress bar\n",
    "batch_size = 1000\n",
    "total_tracks = len(df)\n",
    "\n",
    "for start_idx in tqdm(range(0, total_tracks, batch_size), desc=\"Processing batches\"):\n",
    "    end_idx = min(start_idx + batch_size, total_tracks)\n",
    "    batch_recommendations = []\n",
    "    \n",
    "    for track_idx in range(start_idx, end_idx):\n",
    "        # Get source track info\n",
    "        source_track = df.iloc[track_idx]\n",
    "        \n",
    "        # Get 10 nearest neighbors (excluding self)\n",
    "        distances, indices = knn_model.kneighbors([feature_matrix[track_idx]], n_neighbors=11)\n",
    "        neighbor_indices = indices[0][1:]  # Exclude self (first result)\n",
    "        neighbor_distances = distances[0][1:]  # Exclude self\n",
    "        \n",
    "        # Generate recommendations for this track\n",
    "        for rank, (neighbor_idx, distance) in enumerate(zip(neighbor_indices, neighbor_distances)):\n",
    "            rec_track = df.iloc[neighbor_idx]\n",
    "            \n",
    "            # Calculate similarity score (inverse of distance + 1)\n",
    "            similarity_score = round(1 / (1 + distance), 2)\n",
    "            \n",
    "            # Create recommendation entry matching target format\n",
    "            rec_entry = {\n",
    "                'track_id': source_track['track_id'],\n",
    "                'recommended_track_id': rec_track['track_id'],\n",
    "                'match_score': similarity_score,\n",
    "                'track_name': source_track['track_name'],\n",
    "                'track_artists': source_track['artists'],\n",
    "                'track_album': source_track['album_name'],\n",
    "                'track_genre': source_track['track_genre'],\n",
    "                'track_image_url': '',  # Will be populated later if needed\n",
    "                'track_popularity': source_track['popularity'],\n",
    "                'recommended_track_name': rec_track['track_name'],\n",
    "                'recommended_track_artists': rec_track['artists'],\n",
    "                'recommended_track_album': rec_track['album_name'],\n",
    "                'recommended_track_genre': rec_track['track_genre'],\n",
    "                'recommended_track_image_url': '',  # Will be populated later if needed\n",
    "                'recommended_track_popularity': rec_track['popularity']\n",
    "            }\n",
    "            batch_recommendations.append(rec_entry)\n",
    "    \n",
    "    all_recommendations.extend(batch_recommendations)\n",
    "\n",
    "# Convert to DataFrame\n",
    "recommendations_df = pd.DataFrame(all_recommendations)\n",
    "print(f\"\\nRecommendations generated successfully!\")\n",
    "print(f\"Total recommendations: {len(recommendations_df):,}\")\n",
    "print(f\"Unique source tracks: {recommendations_df['track_id'].nunique():,}\")\n",
    "print(f\"Average recommendations per track: {len(recommendations_df) / recommendations_df['track_id'].nunique():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b11aa",
   "metadata": {},
   "source": [
    "## 8. Validate & Display Sample Recommendations\n",
    "\n",
    "Examine the generated recommendations to ensure quality and proper formatting. We'll look at sample recommendations and verify the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31f7912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample recommendations\n",
    "print(\"Sample recommendations structure:\")\n",
    "display(recommendations_df.head(10))\n",
    "\n",
    "print(f\"\\nDataset statistics:\")\n",
    "print(f\"- Total recommendation pairs: {len(recommendations_df):,}\")\n",
    "print(f\"- Unique source tracks: {recommendations_df['track_id'].nunique():,}\")\n",
    "print(f\"- Unique recommended tracks: {recommendations_df['recommended_track_id'].nunique():,}\")\n",
    "print(f\"- Recommendations per source track: 10\")\n",
    "\n",
    "# Check recommendation quality with a specific example\n",
    "sample_track_id = recommendations_df['track_id'].iloc[0]\n",
    "sample_recs = recommendations_df[recommendations_df['track_id'] == sample_track_id].head(10)\n",
    "\n",
    "print(f\"\\nExample: Recommendations for track ID '{sample_track_id}':\")\n",
    "print(f\"Source: '{sample_recs.iloc[0]['track_name']}' by {sample_recs.iloc[0]['track_artists']}\")\n",
    "print(\"\\nTop 10 recommendations:\")\n",
    "\n",
    "for i, (_, rec) in enumerate(sample_recs.iterrows(), 1):\n",
    "    print(f\"  {i}. '{rec['recommended_track_name']}' by {rec['recommended_track_artists']}\")\n",
    "    print(f\"     Match Score: {rec['match_score']}, Genre: {rec['recommended_track_genre']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9f21b8",
   "metadata": {},
   "source": [
    "## 9. Format Output to Match Target Structure\n",
    "\n",
    "Ensure the output format matches the expected structure from the sample enhanced CSV file. We'll align column names and data types for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f2df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify output format matches target structure\n",
    "if sample_format is not None:\n",
    "    print(\"Verifying output format matches target structure...\")\n",
    "    \n",
    "    target_columns = sample_format.columns.tolist()\n",
    "    current_columns = recommendations_df.columns.tolist()\n",
    "    \n",
    "    print(f\"Target columns: {target_columns}\")\n",
    "    print(f\"Current columns: {current_columns}\")\n",
    "    \n",
    "    # Check if formats match\n",
    "    if set(target_columns) == set(current_columns):\n",
    "        print(\"✓ Column structure matches target format!\")\n",
    "    else:\n",
    "        missing_cols = set(target_columns) - set(current_columns)\n",
    "        extra_cols = set(current_columns) - set(target_columns)\n",
    "        if missing_cols:\n",
    "            print(f\"⚠ Missing columns: {missing_cols}\")\n",
    "        if extra_cols:\n",
    "            print(f\"⚠ Extra columns: {extra_cols}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Using generated recommendation format...\")\n",
    "\n",
    "# Ensure proper data types and formatting\n",
    "recommendations_df['match_score'] = recommendations_df['match_score'].round(2)\n",
    "recommendations_df['track_popularity'] = recommendations_df['track_popularity'].astype(int)\n",
    "recommendations_df['recommended_track_popularity'] = recommendations_df['recommended_track_popularity'].astype(int)\n",
    "\n",
    "print(\"\\nData formatting completed!\")\n",
    "print(f\"Final dataset shape: {recommendations_df.shape}\")\n",
    "print(f\"Final columns: {recommendations_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeade68",
   "metadata": {},
   "source": [
    "## 10. Export Recommendations Dataset\n",
    "\n",
    "Save the complete recommendation dataset to CSV format for use in the recommendation system and dashboard components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b68bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export recommendations to CSV\n",
    "recommendations_df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(f\"Recommendations exported successfully!\")\n",
    "print(f\"Output location: {OUTPUT_CSV.resolve()}\")\n",
    "print(f\"File size: {OUTPUT_CSV.stat().st_size / (1024*1024):.1f} MB\")\n",
    "\n",
    "# Final summary statistics\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"K-NN RECOMMENDATION MODEL SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"✓ Algorithm: k-Nearest Neighbors (k=10)\")\n",
    "print(f\"✓ Distance Metric: Euclidean\")\n",
    "print(f\"✓ Feature Set: 12 standardized audio features\")\n",
    "print(f\"✓ Total Source Tracks: {recommendations_df['track_id'].nunique():,}\")\n",
    "print(f\"✓ Total Recommendations: {len(recommendations_df):,}\")\n",
    "print(f\"✓ Recommendations per Track: 10\")\n",
    "print(f\"✓ Output Format: CSV with match scores\")\n",
    "print(f\"✓ File Location: {OUTPUT_CSV.name}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Display final sample\n",
    "print(\"\\nFinal sample of recommendations:\")\n",
    "sample_data = recommendations_df.sample(10)[['track_name', 'track_artists', 'recommended_track_name', 'recommended_track_artists', 'match_score']]\n",
    "display(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8267b1",
   "metadata": {},
   "source": [
    "## 11. Model Performance & Next Steps\n",
    "\n",
    "The k-NN recommendation model has been successfully built and deployed. The model uses euclidean distance calculations on 12 standardized audio features to find similar songs.\n",
    "\n",
    "### Model Characteristics:\n",
    "- **Algorithm**: k-Nearest Neighbors (k=10)\n",
    "- **Distance Metric**: Euclidean distance on standardized features\n",
    "- **Feature Set**: 12 audio features (danceability, energy, valence, etc.)\n",
    "- **Output**: 10 recommendations per track with similarity scores\n",
    "\n",
    "### Key Benefits:\n",
    "- **No Training Required**: Instant deployment as a lazy learning algorithm\n",
    "- **Interpretable**: Clear similarity based on audio characteristics\n",
    "- **Scalable**: Efficient neighbor search with sklearn implementation\n",
    "- **Consistent**: Standardized features ensure balanced feature contribution\n",
    "\n",
    "### Next Steps:\n",
    "1. **Evaluate Recommendations**: Test with known similar songs for quality assessment\n",
    "2. **Build API Endpoints**: Create functions for real-time recommendation requests\n",
    "3. **Optimize Performance**: Consider approximate nearest neighbor methods for large datasets\n",
    "4. **A/B Testing**: Compare with other recommendation algorithms\n",
    "5. **User Interface**: Integrate with dashboard for interactive recommendations\n",
    "\n",
    "The recommendation dataset is ready for integration into the song recommendation dashboard!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
